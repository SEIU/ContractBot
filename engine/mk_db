#!/usr/bin/env python
"""
Reset ChromaDB and add documents to the database.
"""

from glob import glob
from hashlib import sha1
import json
import os
from pathlib import Path
import sys

import chromadb
import click
from tqdm import tqdm

BATCH_SIZE = 100
CONTEXT_SETTINGS = dict(help_option_names=["-h", "-?", "--help"])


def get_metadata(document: Path) -> str:
    useful_keys = {
        "city": "City",
        "cname": "Document Type",
        "company_name": "Company",
        "division": "Division",
        "effective_date": "Effective Date",
        "employer_name": "Employer",
        "expiration_date": "Expiration",
        "local_now": "Local",
        "membership_size": "Local Size",
        "non_profit_ind": "Nonprofit (Y/N)",
        "notes": "Notes",
        "old_local_name": "Prior Local Number",
        "pdf_unique_name": "Document Name",
        "pub_jur_level": "pub_jur_level",  # Not sure of meaning
        "pub_pri_ind": "pub_pri_ind",  # Not sure of meaning
        "state": "State",
        "unit_size": "Unit Size",
        "upload_time": "Uploaded At",
        "Year": "Year",
        "Org": "Org",
        "Topics": "Topics",
    }
    meta_file = document.with_suffix(".meta")
    metadata: str = ""
    if meta_file.exists():
        meta_items = []
        all_meta = json.loads(meta_file.read_text())
        for k, v in all_meta.items():
            if k in useful_keys and v:  # Key is useful and has a value
                meta_items.append(f"{useful_keys[k]}: {v.removesuffix('.pdf')}")
        metadata = "\n".join(meta_items)

    if "Document Name" not in metadata:
        metadata += f"\nDocument Name: {document.name.removesuffix(".txt")}"
    return metadata


def add_document(
    collection: chromadb.Collection, file_path: str, context_sentences: int = 5
):
    """
    TODO: A better splitter/chunker is almost surely using LangChain
    https://gist.github.com/tazarov/e66c1d3ae298c424dc4ffc8a9a916a4a
    """
    doc_file = Path(file_path)
    document = doc_file.read_text()
    sentences = document.replace("\n", " ").split(".")
    metadata = get_metadata(doc_file)

    chunks = set()
    for i in range(len(sentences) - context_sentences):
        paragraph = ".".join(sentences[i : i + context_sentences])
        content = metadata + "\n.....\n" + paragraph
        chunks.add(content)
    all_chunks = list(chunks)
    all_ids = [sha1(chunk.encode()).hexdigest() for chunk in all_chunks]

    desc = doc_file.name.removesuffix(".txt")[:40].ljust(40)
    for n in tqdm(range(len(chunks) // BATCH_SIZE), desc=desc):
        chunks = all_chunks[n * BATCH_SIZE : (n + 1) * BATCH_SIZE]
        ids = all_ids[n * BATCH_SIZE : (n + 1) * BATCH_SIZE]
        collection.add(documents=chunks, ids=ids)

    return collection


@click.command(context_settings=CONTEXT_SETTINGS)
@click.option(
    "-x", "--reset", is_flag=True, help="Reset the vector database of document chunks"
)
@click.option(
    "-f",
    "--filelist",
    type=str,
    help="File with list of files to process, one per line",
)
@click.option(
    "-c",
    "--collection",
    type=str,
    default="BossBot",
    help="Name of collection to create (default 'BossBot')",
)
@click.option(
    "-n",
    "--num-docs",
    type=int,
    default=sys.maxsize,
    help="Limit processing to N files",
)
@click.option(
    "-p",
    "--pattern",
    type=str,
    help="Generate 'documents.cfg' from glob pattern",
)
def main(reset, filelist, collection, num_docs, pattern):  # type: ignore
    client = chromadb.PersistentClient()
    if reset:
        if os.getenv("ALLOW_RESET") != "TRUE":
            print("DB re-creation permitted only with environment ALLOW_RESET=TRUE")
            sys.exit(-1)
        client.reset()  # Clear the database

    if glob and not filelist:
        files = glob(pattern)
        filelist: str = "documents.cfg"
        Path("documents.cfg").write_text("\n".join(files))

    if filelist:
        files = Path(filelist).read_text().splitlines()
        try:
            collection = client.create_collection(name=collection)
        except:
            collection = client.get_collection(name=collection)

        i = 0
        for document in files:
            i += 1
            if document.startswith("[DONE]"):
                print(f"Existing document {document.removeprefix('[DONE] ')}")
                num_docs += 1  # Add one to get to desired newly processed
                continue
            collection = add_document(collection, document)
            # Mark each completed file back to the filelist
            files[i-1] = f"[DONE] {files[i-1]}"
            Path(filelist).write_text("\n".join(files))
            if i >= num_docs:
                break


if __name__ == "__main__":
    main()
